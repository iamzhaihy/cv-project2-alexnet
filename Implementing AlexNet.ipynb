{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 6433 Project 2: Implementing AlexNet\n",
    "\n",
    "Hongyu Zhai (`hz2162`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "In the original proposal, I planned to use a subset of the ILSVRC2010 training images to train the model. However, the [download link](http://image-net.org/challenges/LSVRC/2010/download-public) no longer works. After consulting Professor Wong, I decided to go with the [CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Keras provides a function to load CIFAR-100\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode=\"fine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides loading the images, `load_data` also splits them into the training and testing sets. There are $50000$ training images, $10000$ testing images, each image has the dimension $(32 x 32 x 3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = X_test.shape[0]\n",
    "n_train = X_train.shape[0]\n",
    "img_shape = X_train.shape[1:]\n",
    "\n",
    "print(\"Number of training examples:\", n_train)\n",
    "print(\"Number of testing examples:\", n_test)\n",
    "print(\"Shape of input images:\", img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure images are properly loaded, we use `matplotlib` to display some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes1 = plt.subplots(5, 5, figsize=(5, 5))\n",
    "for j in range(5):\n",
    "    for k in range(5):\n",
    "        i = np.random.choice(n_train)\n",
    "        axes1[j][k].set_axis_off()\n",
    "        axes1[j][k].imshow(X_train[i:i+1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the AlexNet\n",
    "\n",
    "Then, we follow the original [paper](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) and build the model layer by layer. There are five convolution layers, followed by three fully connected layers.\n",
    "\n",
    "### First Convolution Layer\n",
    "\n",
    "> \"The first convolutional layer filters the 224×224×3 input image with 96 kernels of size 11×11×3 with a stride of 4 pixels.\"\n",
    "\n",
    "> \"The ReLU non-linearity is applied to the output of every convolutional and fully-connected layer.\"\n",
    "\n",
    "> \"Response-normalization layers follow the first and second convolutional layers.\"\n",
    "\n",
    "> \"Max-pooling layers, of the kind described in Section 3.4, follow both response-normalization layers as well as the fifth convolutional layer.\"\n",
    "\n",
    "The original architecture, which was designed for ImageNet images, assumes the input size to be $224 \\times 224 \\times 3$. Since we are using much smaller images, we change the input shape to $32 \\times 32 \\times 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer #1 conv #1\n",
    "l1_conv1 = keras.layers.Conv2D(input_shape=img_shape,\n",
    "                               filters=96,\n",
    "                               kernel_size=(11, 11),\n",
    "                               strides=(4, 4),\n",
    "                               padding='same',\n",
    "                               activation='relu')\n",
    "\n",
    "# response-normalization layer follows the first conv layer\n",
    "l1_conv1_norm = keras.layers.BatchNormalization()\n",
    "\n",
    "# max pooling layer with s = 2, and z = 3\n",
    "l1_conv1_pool = keras.layers.MaxPooling2D(pool_size=(3, 3),\n",
    "                                          strides=(2,2),\n",
    "                                          padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Convolution Layer\n",
    "\n",
    "> \"The second convolutional layer takes as input the (response-normalized and pooled) output of the first convolutional layer and filters it with 256 kernels of size 5 × 5 × 48\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer #2 conv #2\n",
    "l2_conv2 = keras.layers.Conv2D(filters=256,\n",
    "                               kernel_size=(5, 5),\n",
    "                               strides=(1, 1), \n",
    "                               padding='same',\n",
    "                               activation='relu')\n",
    "\n",
    "# response-normalization layer follows the second conv layer\n",
    "l2_conv2_norm = keras.layers.BatchNormalization()\n",
    "\n",
    "# max pooling layer with s = 2, and z = 3\n",
    "l2_conv2_pool = keras.layers.MaxPooling2D(pool_size=(3, 3),\n",
    "                                          strides=(2, 2),\n",
    "                                          padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Convolution Layer\n",
    "\n",
    "> \"The third, fourth, and fifth convolutional layers are connected to one another without any intervening pooling or normalization layers.\"\n",
    "\n",
    "> \"The third convolutional layer has 384 kernels of size 3 × 3 × 256 connected to the (normalized, pooled) outputs of the second convolutional layer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer #3 conv #3\n",
    "l3_conv3 = keras.layers.Conv2D(filters=384,\n",
    "                               kernel_size=(3, 3),\n",
    "                               strides=(1, 1), \n",
    "                               padding='same',\n",
    "                               activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Convolution Layer\n",
    "\n",
    "> \"The fourth convolutional layer has 384 kernels of size 3 × 3 × 192\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer #4 conv #4\n",
    "l4_conv4 = keras.layers.Conv2D(filters=384,\n",
    "                               kernel_size=(3, 3),\n",
    "                               strides=(1, 1), \n",
    "                               padding='same',\n",
    "                               activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth Convolution Layer\n",
    "\n",
    "> \"the fifth convolutional layer has 256 kernels of size 3 × 3 × 192.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer #5 conv #5\n",
    "l5_conv5 = keras.layers.Conv2D(filters=256,\n",
    "                               kernel_size=(3, 3),\n",
    "                               strides=(1, 1), \n",
    "                               padding='same',\n",
    "                               activation='relu')\n",
    "\n",
    "# max pooling layer with s = 2, and z = 3\n",
    "l5_conv5_pool = keras.layers.MaxPooling2D(pool_size=(3, 3),\n",
    "                                          strides=(2,2),\n",
    "                                          padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Fully-Connected Layer\n",
    "\n",
    "> \"The fully-connected layers have 4096 neurons each.\"\n",
    "\n",
    "> \"We use dropout in the first two fully-connected layers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten before feeding to FC layers\n",
    "l6_fc1_flat = keras.layers.Flatten()\n",
    "\n",
    "# layer #6 fc #1\n",
    "l6_fc1 = keras.layers.Dense(4096,\n",
    "                            input_shape=(32,32,3,),\n",
    "                            activation='relu')\n",
    "\n",
    "# dropout with rate 0.5\n",
    "l6_fc1_dropout = keras.layers.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Fully-Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer #7 fc #2\n",
    "l7_fc2 = keras.layers.Dense(4096,\n",
    "                            activation='relu')\n",
    "\n",
    "# dropout with rate 0.5\n",
    "l7_fc2_dropout = keras.layers.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Fully-Connected Layer\n",
    "\n",
    "> \"The output of the last fully-connected layer is fed to a 1000-way softmax which produces a distribution over the 1000 class labels\"\n",
    "\n",
    "The original architecture uses 1000-way softmax because their dataset has 1000 unique class labels. In our case, we will use a 100-way softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer #8 fc #3\n",
    "l8_fc3 = keras.layers.Dense(100,\n",
    "                            activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Everything Together\n",
    "\n",
    "Now we have every layer ready, it is time to put them in a `Sequential` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet = keras.models.Sequential()\n",
    "\n",
    "# first conv layer\n",
    "AlexNet.add(l1_conv1)\n",
    "AlexNet.add(l1_conv1_norm)\n",
    "AlexNet.add(l1_conv1_pool)\n",
    "\n",
    "# second conv layer\n",
    "AlexNet.add(l2_conv2)\n",
    "AlexNet.add(l2_conv2_norm)\n",
    "AlexNet.add(l2_conv2_pool)\n",
    "\n",
    "# third conv layer\n",
    "AlexNet.add(l3_conv3)\n",
    "\n",
    "# fourth conv layer\n",
    "AlexNet.add(l4_conv4)\n",
    "\n",
    "# fifth conv layer\n",
    "AlexNet.add(l5_conv5)\n",
    "AlexNet.add(l5_conv5_pool)\n",
    "\n",
    "# first fc layer\n",
    "AlexNet.add(l6_fc1_flat)\n",
    "AlexNet.add(l6_fc1)\n",
    "AlexNet.add(l6_fc1_dropout)\n",
    "\n",
    "# second fc layer\n",
    "AlexNet.add(l7_fc2)\n",
    "AlexNet.add(l7_fc2_dropout)\n",
    "\n",
    "# third fc layer\n",
    "AlexNet.add(l8_fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model compiled, we can try our model using the CIFAR-100 dataset. Before actually training, however, we need to further process our image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding the labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet.fit(X_train, y_train, batch_size=32, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
